{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML/AI Learning Project - Interactive Tutorial\n",
    "\n",
    "Welcome to the interactive ML/AI learning tutorial! This notebook will guide you through:\n",
    "1. Understanding the data\n",
    "2. Data preprocessing\n",
    "3. Training multiple models\n",
    "4. Evaluating and comparing models\n",
    "5. Making predictions\n",
    "\n",
    "## ðŸŽ¯ Learning Goals\n",
    "- Learn the complete ML workflow\n",
    "- Understand different ML algorithms\n",
    "- Practice with real code examples\n",
    "- Experiment with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's import all necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Our custom modules\n",
    "from ml_project.generate_data import generate_housing_data\n",
    "from ml_project.data_loader import load_data\n",
    "from ml_project.preprocessing import DataPreprocessor, split_data\n",
    "from ml_project.models import LinearRegressionModel, RandomForestModel, NeuralNetworkModel\n",
    "from ml_project.evaluate import evaluate_model, compare_models\n",
    "from ml_project.visualize import (\n",
    "    plot_feature_correlations,\n",
    "    plot_predictions_vs_actual,\n",
    "    plot_residuals,\n",
    "    plot_feature_importance,\n",
    "    plot_model_comparison,\n",
    "    plot_price_distribution\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate and Explore Data\n",
    "\n",
    "Let's create synthetic housing data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate housing data\n",
    "data = generate_housing_data(n_samples=1000, seed=42)\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price distribution\n",
    "plot_price_distribution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for correlations\n",
    "plot_feature_correlations(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing\n",
    "\n",
    "Before training models, we need to:\n",
    "1. Encode categorical variables\n",
    "2. Scale numerical features\n",
    "3. Split data into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Fit and transform data\n",
    "X, y = preprocessor.fit_transform(data)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature names: {preprocessor.feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split training for validation\n",
    "X_train, X_val, y_train, y_val = split_data(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Models\n",
    "\n",
    "Let's train three different types of models:\n",
    "1. **Linear Regression**: Simple baseline model\n",
    "2. **Random Forest**: Ensemble tree-based model\n",
    "3. **Neural Network**: Deep learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression\n",
    "lr_model = LinearRegressionModel()\n",
    "lr_model.train(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "lr_metrics, lr_pred = evaluate_model(lr_model, X_test, y_test)\n",
    "\n",
    "print(f\"\\nLinear Regression Results:\")\n",
    "print(f\"RMSE: ${lr_metrics['rmse']:,.2f}\")\n",
    "print(f\"RÂ² Score: {lr_metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rf_model = RandomForestModel()\n",
    "rf_model.train(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "rf_metrics, rf_pred = evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "print(f\"\\nRandom Forest Results:\")\n",
    "print(f\"RMSE: ${rf_metrics['rmse']:,.2f}\")\n",
    "print(f\"RÂ² Score: {rf_metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural Network\n",
    "nn_model = NeuralNetworkModel()\n",
    "nn_model.build_model(X_train.shape[1])\n",
    "\n",
    "# Display model architecture\n",
    "print(\"Neural Network Architecture:\")\n",
    "nn_model.model.summary()\n",
    "\n",
    "# Train (this may take a minute)\n",
    "history = nn_model.train(X_train, y_train, X_val, y_val, verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "nn_metrics, nn_pred = evaluate_model(nn_model, X_test, y_test)\n",
    "\n",
    "print(f\"\\nNeural Network Results:\")\n",
    "print(f\"RMSE: ${nn_metrics['rmse']:,.2f}\")\n",
    "print(f\"RÂ² Score: {nn_metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare Models\n",
    "\n",
    "Let's compare all three models side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results = {\n",
    "    'Linear Regression': lr_metrics,\n",
    "    'Random Forest': rf_metrics,\n",
    "    'Neural Network': nn_metrics\n",
    "}\n",
    "\n",
    "# Compare\n",
    "best_model = compare_models(results)\n",
    "\n",
    "# Visualize comparison\n",
    "plot_model_comparison(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Best Model\n",
    "\n",
    "Let's dive deeper into the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Random Forest for analysis (typically best)\n",
    "best_model = rf_model\n",
    "best_pred = rf_pred\n",
    "\n",
    "# Predictions vs Actual\n",
    "plot_predictions_vs_actual(y_test, best_pred, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "plot_residuals(y_test, best_pred, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance = rf_model.get_feature_importance(preprocessor.feature_names)\n",
    "plot_feature_importance(importance, top_n=8, model_name='Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Make Predictions\n",
    "\n",
    "Now let's use our trained model to predict prices for new houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new house\n",
    "new_house = pd.DataFrame([{\n",
    "    'square_feet': 2800,\n",
    "    'bedrooms': 4,\n",
    "    'bathrooms': 3,\n",
    "    'year_built': 2018,\n",
    "    'lot_size': 12000,\n",
    "    'garage_spaces': 2,\n",
    "    'neighborhood': 'Suburbs',\n",
    "    'house_type': 'Single-Family'\n",
    "}])\n",
    "\n",
    "# Preprocess\n",
    "new_house_processed = preprocessor.transform(new_house)\n",
    "\n",
    "# Predict with all models\n",
    "print(\"Price Predictions for New House:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Linear Regression:  ${lr_model.predict(new_house_processed)[0]:,.2f}\")\n",
    "print(f\"Random Forest:      ${rf_model.predict(new_house_processed)[0]:,.2f}\")\n",
    "print(f\"Neural Network:     ${nn_model.predict(new_house_processed)[0]:,.2f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Exercises for Learning\n",
    "\n",
    "Try these exercises to deepen your understanding:\n",
    "\n",
    "1. **Experiment with hyperparameters**:\n",
    "   - Change `n_estimators` in Random Forest\n",
    "   - Modify neural network architecture\n",
    "   - Adjust learning rate\n",
    "\n",
    "2. **Feature engineering**:\n",
    "   - Create new features (e.g., price per square foot)\n",
    "   - Try removing features and see impact\n",
    "\n",
    "3. **Different models**:\n",
    "   - Try XGBoost or LightGBM\n",
    "   - Implement ensemble methods\n",
    "\n",
    "4. **Cross-validation**:\n",
    "   - Implement k-fold cross-validation\n",
    "   - Compare results across folds\n",
    "\n",
    "5. **Real data**:\n",
    "   - Use a real dataset from Kaggle\n",
    "   - Apply the same workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Key Takeaways\n",
    "\n",
    "1. **Data preprocessing is crucial**: Proper scaling and encoding can significantly impact model performance\n",
    "2. **Different models have different strengths**: Tree-based models often work well without much tuning\n",
    "3. **Always use a test set**: Never evaluate on training data\n",
    "4. **Visualize your results**: Plots help identify issues and communicate findings\n",
    "5. **Start simple**: Begin with simple models before moving to complex ones\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "- Explore the codebase in `src/ml_project/`\n",
    "- Run the standalone scripts: `train.py`, `predict.py`\n",
    "- Read about ML concepts in the resources listed in README\n",
    "- Work on your own ML project!\n",
    "\n",
    "**Happy Learning! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
